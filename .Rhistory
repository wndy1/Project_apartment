x11()
plot(resid(reg.train),main="잔차 vs 인덱스")
x11()
plot(resid(reg.train)~X1)
x11()
plot(resid(reg.train)~X2)
x11()
plot(resid(reg.train)~X3)
x11()
plot(resid(reg.train),X3)
x11()
plot(resid(reg.train)~X3)
x11()
plot(resid(reg.train)~X4)
x11()
plot(resid(reg.train)~X5)
x11()
plot(resid(reg.train)~X6)
x11()
plot(resid(reg.train)~X7)
x11()
plot(resid(reg.train)~X8)
x11()
plot(resid(reg.train)~X9)
x11()
plot(resid(reg.train),main="잔차 vs 인덱스")
x11()
plot(resid(reg.train),main="잔차 vs 인덱스",ylab="잔차")
x11()
plot(resid(reg.train),main="잔차 vs 인덱스",ylab="잔차")
x11()
hist(res.train)
x11()
corrplot.mixed(cor(train[,2:15]))
x11()
plot(valid.hat1~valid$평균매매가)
x11()
qqnorm(res.train)
qqline(res.train,col=2)
x11()
qqnorm(res.train,main="정규확률그림")
qqline(res.train,col=2)
x11()
qqnorm(res.train,main="정규확률그림")
qqline(res.train,col=2)
x11()
plot(res.train ~ fitted(reg.train))
x11()
plot(cooks.distance(reg.train))
# 독립성 검정
durbinWatsonTest(reg.train)
x11()
plot(res.train ~ fitted(reg.train))
x11()
plot(res.train ~ fitted(reg.train),main="잔차 vs 적합값")
x11()
plot(res.train ~ fitted(reg.train),main="잔차 vs 적합값",ylab="residuals")
# x11()
# pairs(Y~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X12+X13+X14+X15,data = train)
vif(reg.train)>10
x11()
plot(valid.hat1~valid$평균매매가)
# X11 제거 후 train MSE
sum(reg.train2$residuals^2)/(nrow(train)-13)
# X11 제거 후 validation MSE
sum(e2^2)/(n-p2-1)
rm(list=ls())
# p.271
# sample 추출
m=c()
for(i in 1:100){
set.seed(i)
m[i]=mean(sample(x=0:9,size=5,replace=T))
}
m
x11()
hist(m)
# 특정 다른분포의 모집단 -> 추출 중심극한정리?
n = c()
rpois(100,3)
for(i in 1:100){
set.seed(i)
n[i]=mean(rpois(100,3))
}
x11()
hist(n)
n1 = c()
for(i in 1:1000){
set.seed(i)
n1[i]=mean(rpois(1000,3))
}
x11()
hist(n1)
x11()
par(mfrow=c(2,1))
hist(n)
hist(n1)
x11()
par(mfrow=c(1,2))
hist(n)
hist(n1)
# 특정 다른분포의 모집단 -> 추출 중심극한정리?
# X1,...Xn ~ B(n,p=0.3)
n = c()
for(i in 1:100){
set.seed(i)
n[i]=mean(rbinom(100,2,0.3))
}
x11()
hist(n)
n1 = c()
for(i in 1:1000){
set.seed(i)
n1[i]=mean(rbinom(1000,2,0.3))
}
x11()
par(mfrow=c(1,2))
hist(n)
hist(n1)
rm(list=ls())
### Regression Model ###
# library
library(moments)
library(nortest)
library(car)
library(corrplot)
# set directory
setwd("C:/Users/wndy4/Desktop/Project_apartment")
## load train set, validation set, test set
train = read.csv('train set.csv',header = T,stringsAsFactors = F)
valid = read.csv('validation set.csv',header = T,stringsAsFactors = F)
test = read.csv('test set.csv',header = T,stringsAsFactors = F)
# 불필요한 열 제거
train = train[,-c(1,2,3)]
valid = valid[,-c(1,2,3)]
test = test[,-c(1,2,3)]
##
colnames(train)
colnames(valid)
colnames(test)
# categorical variable
table(train$개발호재)
## Multiple regression model
# Model : Y = B0 + B1X1 + B2X2 + ... + BpXp + E
# 변수 설정
Y = train$평균매매가
X1 = train$분양면적
X2 = train$단지세대수
X3 = train$개별세대수
X4 = train$노후도
X5 = train$역세권점수
X6 = train$평균전세가
X7 = train$토지면적
X8 = train$문화시설수
X9 = train$쇼핑시설수
X10 = train$스타벅스
X11 = train$평균인구수
X12 = train$평균세대수
X13 = train$교육시설수
X14 = train$개발호재
X15 = train$평균혼인건수
# 회귀 적합
reg.train = lm(Y~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X12+X13+factor(X14)+X15,data=train)
e_t = train$평균매매가 - fitted(reg.train)
sum(e_t^2)/(nrow(train)-14)
# 초기모형 train MSE : 1369.551
sum(reg.train$residuals^2)/(nrow(train)-14)
summary(reg.train)
# validation set으로 모델 평가
coef = reg.train$coefficients
valid.mat = valid
valid.mat[,1] = 1
valid.mat = as.matrix(valid.mat)
View(valid.mat)
# predict valid.hat
valid.hat = as.vector(coef%*%t(valid.mat))
e = valid$평균매매가 - valid.hat
n = nrow(valid)
p = 15
x11()
plot(valid.hat~valid$평균매매가)
# 초기모형 validaiton MSE 구하기
sum(e^2)/(n-p-1) # 1220.949
# adjusted R2 구하기
SSE.valid = sum(e^2)
SST.valid = sum((valid$평균매매가-mean(valid$평균매매가))^2)
SSE.valid
SST.valid
ad.R2.valid = 1-((SSE.valid/(n-p-1))/(SST.valid/(n-1)))
ad.R2.valid # 0.7881567
valid.mat = valid
valid.mat[,1] = 1
valid.mat = as.matrix(valid.mat)
View(valid.mat)
# predict valid.hat
valid.hat = as.vector(coef%*%t(valid.mat))
## 모형 진단하기
summary(reg.train)
x11()
plot(reg.train)
x11()
plot(fitted(reg.train)~train$평균매매가)
# outlier 판단
x11()
plot(cooks.distance(reg.train))
# outlier가 있다고 판단되자만
# 독립성 검정
durbinWatsonTest(reg.train)
# 더빈 왓슨 통계량이 2보다 크므로, 자기상관성이 없다고 볼 수 있다.
# 선형성
res.train = resid(reg.train)
x11()
plot(res.train ~ fitted(reg.train),main="잔차 vs 적합값",ylab="residuals")
# 등분산성
x11()
plot(resid(reg.train),main="잔차 vs 인덱스",ylab="잔차")
x11()
plot(rstandard(reg.train))
x11()
plot(rstudent(reg.train))
## 정규성 검정
# histogram
x11()
hist(res.train)
# skewness & kurtosis
skewness(res.train)
agostino.test(res.train) # p-value가 유의수준 0.05보다 작으므로 skewness는 0이 아니라 할 수 있다.
kurtosis(res.train)
anscombe.test(res.train) # p-vlaue가 유의수준 0.05보다 작으므로 kurtosis는 3이 아니라 할 수 있다.
shapiro.test(res.train)
lillie.test(res.train)
ad.test(res.train)
x11()
qqnorm(res.train,main="정규확률그림")
qqline(res.train,col=2)
# 잔차의 정규성에 대한 검정은 맞지 않다고 하지만, 중심극한정리에 따라 샘플의 수가 많기 때문에 상관없다?
## 다중공선성
x11()
corrplot.mixed(cor(train[,2:15]))
# x11()
# pairs(Y~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X12+X13+X14+X15,data = train)
vif(reg.train)>10
# vif > 10 다중공선성이 존재한다고 볼 수 있다.
# X11과 X12이 다중공선성이 존재한다고 볼 수 있다.
# X11 : 평균인구수
# X12 : 평균세대수
# 평균인구수와 평균세대수의 상관관계 분석
cor(X11,X12)
cor(Y,X11)
cor(Y,X12)
x11()
plot(X11,X12)
summary(reg.train)
### VIF 존재에 따른 모델 선택
## 원래 모델에 variable selection
## X11 제거 후 or X12 제거 후 비교해서 회귀모형 진단후 variable selection
## 1. 원래 모델에 variable selection
reg.train1 = lm(Y~1,data=train)
# stepwise selection
step(reg.train1, scope = list(upper = reg.train,lower = reg.train1),direction = 'both')
# Y ~ X6 + X4 + X13 + factor(X14) + X5 + X9 + X11 + X12 + X2 + X15 + X7 + x8
# 빠진 변수 : X1, X3, X10
reg.train.stepwise1 = lm(Y ~ X2+X4+X5+X6+X7+X8+X9+X11+X12+X13+factor(X14)+X15,data=train)
coef.stepwise1 = reg.train.stepwise1$coefficients
summary(reg.train.stepwise1)
# 초기모형 stepwise variable selection train MSE
sum(reg.train.stepwise1$residuals^2)/(nrow(train)-)
sum((train$평균매매가 - fitted(reg.train.stepwise1))^2)/(nrow(train)-11)
# 1367.26
# predict valid.hat
valid.mat1 = valid[,-c(2,4,11)]
valid.mat1[,1] = 1
valid.mat1 = as.matrix(valid.mat1)
valid.hat1 = as.vector(coef.stepwise1%*%t(valid.mat1))
e1 = valid$평균매매가 - valid.hat1
n = nrow(valid)
p1 = 12
x11()
plot(valid.hat1~valid$평균매매가)
# 초기모형 stepwise variable selection validation MSE 구하기
sum(e1^2)/(n-p1-1)
# 기존 1220.949에서 1217.055로 감소
# adjusted R2 구하기
SSE.valid1 = sum(e1^2)
SST.valid1 = sum((valid$평균매매가-mean(valid$평균매매가))^2)
SSE.valid1
SST.valid1
ad.R2.valid1 = 1-((SSE.valid1/(n-p1-1))/(SST.valid1/(n-1)))
ad.R2.valid1 # 0.7888323으로 기존보다 증가
sqrt(vif(reg.train.stepwise1))>sqrt(10)
# X11과 X12 공선성 존재
## 2. X11 제거 후 variable selection 진행
reg.train2 = lm(Y~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X12+X13+factor(X14)+X15,data=train)
summary(reg.train2)
# X11 제거 후 train MSE
sum(reg.train2$residuals^2)/(nrow(train)-13)
# 1527.122
vif(reg.train2)>10
# validation set 을 통한 검증
coef2 = reg.train2$coefficients
valid.mat2 = valid[,-12]
valid.mat2[,1] = 1
valid.mat2 = as.matrix(valid.mat2)
View(valid.mat)
# predict valid.hat
valid.hat2 = as.vector(coef2%*%t(valid.mat2))
e2 = valid$평균매매가 - valid.hat2
n = nrow(valid)
p2 = 14
# X11 제거 후 validation MSE
sum(e2^2)/(n-p2-1)
# 1347.754로 1220.949보다 높다
# 잔차 분석
x11()
plot(reg.train2)
x11()
plot(resid(reg.train2))
x11()
plot(resid(reg.train2)~fitted(reg.train2))
durbinWatsonTest(reg.train2)
# variable selection 진행
reg.train1 = lm(Y~1,data=train)
# stepwise selection
step(reg.train1, scope = list(upper = reg.train2,lower = reg.train1),direction = 'both')
# Y ~ X6 + X4 + X13 + X10 + factor(X14) + X5 + X9 + X7 + x1 + X15 + X2 + X3
# 빠진 변수 : X8, X12
reg.train.stepwise2 = lm(Y ~ X1+X2+X3+X4+X5+X6+X7+X9+X10+X13+factor(X14)+X15,data=train)
coef.stepwise2 = reg.train.stepwise2$coefficients
summary(reg.train.stepwise2)
# X11 제거후 stepwise train MSE
sum(reg.train.stepwise2$residuals^2)/(nrow(train)-11)
# 1525.889
vif(reg.train.stepwise2)>10
# forward
step(reg.train1, scope = list(upper = reg.train2,lower = reg.train1),direction = 'forward')
# X11 제거후 stepwise validation mse 비교
valid.mat2_2 = valid[,-c(9,12,13)]
valid.mat2_2[,1] = 1
valid.mat2_2 = as.matrix(valid.mat2_2)
# predict valid.hat
valid.hat2_2 = as.vector(coef.stepwise2%*%t(valid.mat2_2))
e2_2 = valid$평균매매가 - valid.hat2_2
n = nrow(valid)
p2_2 = 12
# X11 제거후 validaiton MSE
sum(e2_2^2)/(n-p2_2-1)
# 1348.721
## 3. X12 제거 후 variable selection 진행
reg.train3 = lm(Y~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X13+factor(X14)+X15,data=train)
summary(reg.train3)
# X12 제거후 train MSE
sum(reg.train3$residuals^2)/(nrow(train)-13)
# 1509.502
vif(reg.train3)>10
# validation set 을 통한 검증
coef3 = reg.train3$coefficients
valid.mat3 = valid[,-13]
valid.mat3[,1] = 1
valid.mat3 = as.matrix(valid.mat3)
# predict valid.hat
valid.hat3 = as.vector(coef3%*%t(valid.mat3))
e3 = valid$평균매매가 - valid.hat3
n = nrow(valid)
p3 = 14
# X12 제거후 validation MSE
sum(e3^2)/(n-p3-1)
# 1328.958로 X11 제거시(1347.754)보다 낮고, origin(1220.949)보다는 높다
# 잔차 분석
x11()
plot(reg.train3)
x11()
plot(resid(reg.train3))
x11()
plot(resid(reg.train3)~fitted(reg.train3))
durbinWatsonTest(reg.train3)
# variable selection 진행
reg.train1 = lm(Y~1,data=train)
# stepwise selection
step(reg.train1, scope = list(upper = reg.train3,lower = reg.train1),direction = 'both')
# Y ~ X6 + X4 + X13 + X10 + factor(X14) + X5 + X9 + X11 + x7 + X15 + X1 + X2
# 빠진 변수 : X3, X8
reg.train.stepwise3 = lm(Y ~ X1+X2+X4+X5+X6+X7+X9+X10+X11+X13+factor(X14)+X15,data=train)
coef.stepwise3 = reg.train.stepwise3$coefficients
summary(reg.train.stepwise3)
reg.train.stepwise3$coefficients
# X12 제거후 stepwise train MSE
sum(reg.train.stepwise3$residuals^2)/(nrow(train)-11)
# 1511.268
vif(reg.train.stepwise3)>10
# X12 제거후 stepwise validation mse 비교
valid.mat3_1 = valid[,-c(4,9,13)]
valid.mat3_1[,1] = 1
valid.mat3_1 = as.matrix(valid.mat3_1)
# predict valid.hat
valid.hat3_1 = as.vector(coef.stepwise3%*%t(valid.mat3_1))
e3_1 = valid$평균매매가 - valid.hat3_1
n = nrow(valid)
p3_1 = 12
# MSE
sum(e3_1^2)/(n-p3_1-1)
# 1348.721
# 1334.331로 X11제거후 variable selection(1348.721)보다 낮지만, orign varable selection(1217.055)보다는 높다
# stepwise, X12(평균 세대수)를 뺀 회귀모형 적용
# test MSE
View(test)
test.mat = test[,-c(4,9,13)]
test.mat[,1] = 1
test.mat = as.matrix(test.mat)
# predict test set
test_hat = as.vector(coef.stepwise3%*%t(test.mat))
e_test = test$평균매매가 - test_hat
sum(e_test^2)/(n-11)
graphics.off()
# 최종모형 선택은 다중공선성을 제거를 위해 X12 변수를 제거하고 stepwise을 통해 변수선택된 모형이다.
# validation MSE도 train MSE에 비해 낮아졌다.
# 해석
reg.train.stepwise3 = lm(Y ~ X1+X2+X4+X5+X6+X7+X9+X10+X11+X13+factor(X14)+X15,data=train)
final.reg = reg.train.stepwise3
final.reg$coefficients
round(sort(final.reg$coefficients,decreasing = T),4)
# X14 : 개발호재, 18.8459로 모델의 변수 중에서 가장 높다
# X5 : 역세권점수, 6.7173
# X10 : 스타벅스, 3.7135
# X13 : 교육시설수, 2.21412
# X6 : 평균전세가 : 0.6467
# X1 : 분양면적 : 0.0964
# X2 : 단지세대수 : 0.0042
# X11 : 평균인구수 : 0.0002
# X15 : 평균혼인건수 : -0.0616
# X9 : 쇼핑시설수 : -0.3640
# X7 : 토지면적, -0.6610
# X4 : 노후도 : -1.9706
# 집값에 많은 영향을 준다고 잘 알려진 변수들이 상위권에 존재한다.
# 개발호재가 인천아파트 평균매매가 형성에 많은 영향을 주는 것을 알 수 있고
# 역세권점수 또한 예상 가능했다. 반면에 스타벅스가 교육시설수보다 계수가 높은 것은 신선하다
x11()
plot(reg.train2)
x11()
plot(resid(reg.train2))
durbinWatsonTest(reg.train2)
x11()
plot(resid(reg.train2)~fitted(reg.train2))
x11()
plot(resid(reg.train2))
x11()
plot(resid(reg.train2),main="평균인구수(X11)제거 후 잔차 vs 인덱스")
x11()
plot(resid(reg.train2)~fitted(reg.train2))
x11()
qqnorm(resid(reg.train2))
qqline(resid(reg.train2),col=2)
x11()
plot(resid(reg.train2)~fitted(reg.train2))
x11()
qqnorm(resid(reg.train2))
qqline(resid(reg.train2),col=2)
x11()
qqnorm(resid(reg.train2),main="평균인구수(X11)제거 후 정규확률그림")
qqline(resid(reg.train2),col=2)
x11()
plot(resid(reg.train2)~fitted(reg.train2))
x11()
plot(resid(reg.train2)~fitted(reg.train2),main="평균인구수(X11)제거 후 잔차 vs 예측값")
durbinWatsonTest(reg.train2)
# 1525.889
vif(reg.train.stepwise2)>10
x11()
plot(reg.train.stepwise2)
x11()
plot(resid(reg.train.stepwise2),main="평균인구수(X11)제거 후 stepwise 잔차 vs 인덱스")
x11()
plot(resid(reg.train.stepwise2),main="평균인구수(X11)제거 후 stepwise 잔차 vs 인덱스")
x11()
plot(resid(reg.train.stepwise2)~fitted(reg.train.stepwise2),main="평균인구수(X11)제거 후 stepwise 잔차 vs 예측값")
x11()
qqnorm(resid(reg.train.stepwise2),main="평균인구수(X11)제거 후 stepwise 정규확률그림")
qqline(resid(reg.train.stepwise2),col=2)
durbinWatsonTest(reg.train.stepwise2)
# X11 제거후 validaiton MSE
sum(e2_2^2)/(n-p2_2-1)
## 3. X12 제거 후 variable selection 진행
reg.train3 = lm(Y~X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X13+factor(X14)+X15,data=train)
x11()
plot(reg.train3)
x11()
plot(resid(reg.train3),main="평균세대수(X12)제거 후 잔차 vs 인덱스")
x11()
plot(resid(reg.train3)~fitted(reg.train3),main="평균세대수(X12)제거 후 잔차 vs 예측값")
x11()
qqnorm(resid(reg.train3),main="평균세대수(X12)제거 후 정규확률그림")
qqline(resid(reg.train3),col=2)
durbinWatsonTest(reg.train3)
x11()
plot(reg.train.stepwise3)
x11()
plot(resid(reg.train.stepwise3),main="평균세대수(X12)제거 후 stepwise 잔차 vs 인덱스")
x11()
plot(resid(reg.train.stepwise3)~fitted(reg.train.stepwise3),main="평균세대수(X12)제거
x11()
plot(resid(reg.train.stepwise3)~fitted(reg.train.stepwise3),main="평균세대수(X12)제거 후 stepwise 잔차 vs 예측값")
x11()
plot(resid(reg.train.stepwise3)~fitted(reg.train.stepwise3),main="평균세대수(X12)제거 후 stepwise 잔차 vs 예측값")
x11()
qqnorm(resid(reg.train.stepwise3),main="평균세대수(X12)제거 후 stepwise 정규확률그림")
qqline(resid(reg.train.stepwise3),col=2)
# X12 제거후 stepwise train MSE
sum(reg.train.stepwise3$residuals^2)/(nrow(train)-11)
summary(reg.train.stepwise3)
summary(reg.train3)
round(sort(final.reg$coefficients,decreasing = T),4)
final.reg$coefficients
round(sort(final.reg$coefficients,decreasing = T),4)
