# 몬테칼로 방법(결국 사후표본으로 추정) 로그오즈비 추정치와 표준오차 게산
mean(xi); sd(xi)
# 로그오즈비 사후밀도함수와 95% HPD 표시
HPD = HPDsample(theta = xi,level = 0.95)
windows()
plot(density(xi),type = 'l',lwd = 3,ylab = 'density',xlab = '로즈오즈비',
main = '로그오즈비 사후밀도함수와 HPD')
abline(v = HPD,lwd=2,lty=2,col=2)
legend("topright",legend=c("사후밀도함수","95% 최대사후구간"),lwd=c(3,2),lty = c(1,2),col = c("black",2))
rm(list=ls())
library(qcc) # quality control chart
## 예제 12 ------------------------------------------------------------------
# 자료 입력
death <- c(2,1,2,4,2,5,3,3,5,6,3,8,3,
3,6,3,6,5,3,5,2,6,2,3,4,3,
2,9,2,2,3,2,7,3,2,10,6,2,3,
1,2,3,3,4,3,2,6,2,2,3,2,3,
4,3,2,3,5,2,5,5,3,4,3,6,2,
1,2,3,2,6,3,3,6,3,2,3,6,4,
6,5,3,5,6,2,6,3,2,3,2,6,2,
6,3,3,2,6,9,6,3,6,6,2,3,2,
3,5,3,5,2,3,2,3,3,1,3,3,2,
3,3,4,3,6,6,3,3,3,2,3,3,6)
freq = table(death)
cause = c('감염','암','순환기','호흡기','소화기','사고사','비뇨기','정신병','노환','신경계')
windows()
par(mfrow=c(2,2))
barplot(freq, col=rainbow(10), main='death',legend.text = cause, args.legend = list(x = 'topright'))
pie(freq,label = cause, col=rainbow(10), main = 'death')
pareto.chart(freq, main='death',xlab='질병종류',ylab='도수',ylab2 = '누적상대도수')
## 예제 13 ------------------------------------------------------------------
# 자료 입력
drink <- c(101.8,101.5,101.8,102.6,101,96.8,102.4,100,98.8,98.1,
98.8,98,99.4,95.5,100.1,100.5,97.4,100.2,101.4,98.7,
101.4,99.4,101.7,99,99.7,98.9,99.5,100,99.7,100.9,
99.7,99,98.8,99.7,100.9,99.9,97.5,101.5,98.2,99.2,
98.6,101.4,102.1,102.9,100.8,99.4,103.7,100.3,100.2,101.1,
101.8,100,101.2,100.5,101.2,101.6,99.9,100.5,100.4,98.1,
100.1,101.6,99.3,96.1,100,99.7,99.7,99.4,101.5,100.9,
101.3,99.9,99.1,100.7,100.8,100.8,101.4,100.3,98.4,97.2)
windows()
hist(drink,freq = F)
lines(x = hist.result$mids,y = hist.result$density,type = 'b',pch=10)
library(psych)
describe(drink) # 기술통계량 표시, 위치측도(평균, 중앙값), 산포측도(표본분산,범위), 모양 측도(왜도, 첨도)
a=describe(drink) # 기술통계량 표시, 위치측도(평균, 중앙값), 산포측도(표본분산,범위), 모양 측도(왜도, 첨도)
a$kurtosis
alpha = 0.05
pnorm(1.96,0,1)
pnorm(1.96,0,1,lower.tail = F)
qnorm(alpha/2,0,1)
qnorm(alpha/2,0,1,lower.tail = F)
rm(list=ls())
height <- c(163, 161, 168, 161, 157, 162, 153, 159, 164, 170,
152, 160, 157, 168, 150, 165, 156, 151, 162, 150,
156, 152, 161, 165, 168, 167, 165, 168, 159, 156)
windows()
boxplot(height)
windows()
par(mfrow=c(1,2))
hist(height)
boxplot(height)
var(height)
# 데이터 개요
summary(height)
windows()
par(mfrow=c(1,2))
hist(height)
boxplot(height)
# 정규성 확인
library(moments)
windows()
qqnorm(height)
qqline(height,col=2)
# 왜도, 왜도 0인지에 대한 검정
skewness(height)
agostino.test(height)
# 첨도, 첨도 3인지에 대한 검정
kurtosis(height)
anscombe.test(height)
# 정규성 검정
shapiro.test(height)
library(nortest)
ad.test(height)
lillie.test(height)
# 정규성 검정
shapiro.test(height)
# 신뢰구간
mean = mean(height)
sd = sd(height)
n = length(height)
# t-분포를 이용한 신뢰구간 -> t분포를 하는 것이 정확하다
n
alpha = 0.05
talpha = qt(1-alpha/2,n-1)
# talpha = qt(alpha/2,n-1,lower.tail = F)
lci_t = mean-talpha*(sd/sqrt(n))
uci_t = mean+talpha*(sd/sqrt(n))
ci_t=c(lci_t,uci_t)
ci_t
# n이 30이기에 CLT에 따라 정규분포를 이용해 근사적으로 신뢰구간을 구할 수 있다.
# 정규분포를 이용한 신뢰구간 -> 근사적이기 때문에 t분포보다는 정확하지 않다
zalpha = qnorm(1-alpha/2)
lci_z = mean-zalpha*sd/sqrt(n)
uci_z = mean+zalpha*sd/sqrt(n)
ci_z=c(lci_z,uci_z)
ci_z
# t분포를 이용한 검정
tvalue = (mean - 159)/(sd/sqrt(n))
t.test(height,mu=159)
t.test(height,mu=159,alternative = "two.sided")
mean(height)
# 정규분포를 이용한 검정
zvalue = (mean - 159)/(sd/sqrt(n))
install.packages('htest')
pvalue = 2*pnorm(abs(zvalue),lower.tail = F)
pvalue
rm(list=ls())
?moments
### noise data ###
noise <- c(55.9, 63.8, 57.2, 59.8, 65.7, 62.7, 60.8, 51.3, 61.8, 56.0,
66.9, 56.8, 66.2, 64.6, 59.5, 63.1, 60.6, 62.0, 59.4, 67.2,
63.6, 60.5, 66.8, 61.8, 64.8, 55.8, 55.7, 77.1, 62.1, 61.0,
58.9, 60.0, 66.9, 61.7, 60.3, 51.5, 67.0, 60.2, 56.2, 59.4,
67.9, 64.9, 55.7, 61.4, 62.6, 56.4, 56.4, 69.4, 57.6, 63.8)
windows()
par(mfrow=c(1,2))
hist(noise)
boxplot(noise)
# 왜도, 첨도
skewness(noise)
agostino.test(noise)
# p_value가 유의수준 0.05보다 크므로 왜도가 0이라 할 수 있다.
kurtosis(noise)
anscombe.test(noise)
windows()
qqnorm(noise)
qqline(noise,lty=2,col=2)
# 기술통계량
mean(noise)
sd(noise)
median(noise)
length(noise)
# 정규성 검정
shapiro.test(noise)
ad.test(noise)
lillie.test(noise)
# 신뢰구간 구하기
# 정규성을 만족하기 때문에 정확히 t분포는 만족한다.
# 근사적으로 z분포를 만족할 수 있다.
# t분포 이용
x_bar = mean(noise)
s = sd(noise)
n = length(noise)
alpha = 0.05
talpha = qt(alpha/2,n-1,lower.tail = F)
talpha
c(x_bar-talpha*(s/sqrt(n)),x_bar + talpha*(s/sqrt(n)))
# z분포 이용도 가능
zalpha = qnorm(alpha/2,0,1,lower.tail = F)
c(x_bar-zalpha*(s/sqrt(n)),x_bar + zalpha*(s/sqrt(n)))
# 가설검정
# H0 : mu = 61 vs. H1 mu > 61
# t test
mu = 61
t_val = (x_bar - mu)/(s/sqrt(n))
t_val
pt(t_val,n-1)
pt(t_val,n-1,lower.tail = F)
?t.test
# 유의수준 0.05보다 크므로 귀무가설을 기각할 수 없다.
t.test(noise,mu=61,alternative = "greater")
pt(t_val,n-1,lower.tail = F)
# z test
z_val = t_val
pnorm(z_val,0,1,lower.tail = F)
x = seq(-3,3,length = 1000)
y = pt(x,n-1)
windows()
plot(x,y)
y = pt(x,n-1,lower.tail = F)
windows()
plot(x,y)
y = dt(x,n-1)
windows()
plot(x,y)
x = seq(-4,4,length = 1000)
y = dt(x,n-1)
windows()
plot(x,y,type='l')
windows()
plot(x,y,type='l')
abline(v=qt(alpha,n-1),col=2)
abline(v=qt(alpha,n-1,lower.tail = F),col=2)
abline(v = t_val,col="blue")
windows()
plot(x,y,type='l')
abline(v = c(x_bar-talpha*(s/sqrt(n)),x_bar + talpha*(s/sqrt(n))),col=2,lty=2)
x = seq(-4,4,length = 1000)
y = dnorm(x,0,1)
windows()
plot(x,y,type='l')
y_t = dt(x,n-1)
lines(y_t,col=2,lty=2)
y_t = dt(x,n-1)
windows()
plot(x,y,type='l')
lines(x,y_t,col=2,lty=2)
## 예제 05 ------------------------------------------------------------------
# 자료 입력
height <- c(181,161,170,160,158,168,162,179,183,178,171,177,163,158,160,160,158,
173,160,163,167,165,163,173,178,170,167,177,175,169,152,158,160,160,
159,180,169,162,178,173,173,171,171,170,160,167,168,166,164,173,180)
weight <- c(78,49,52,53,50,57,53,54,71,73,55,73,51,53,65,48,59,
64,48,53,78,45,56,70,68,59,55,64,59,55,38,45,50,46,
50,63,71,52,74,52,61,65,68,57,47,48,58,59,55,74,74)
x = height
y = weight
windows()
plot(x,y,type='p', xlab = "height(cm)",ylab='weight(kg)',main = '키와 몸무게 산점도')
# 우상향으로 증가하는 경향, But 분산의 증가가 보인다?
# 상관계수
cor(x,y)
cor.test(x,y,method = "spearman")
fit1 = lm(y ~ x)
f_s = summary(fit1)
f_s
# 머리색깔과 눈색깔
haireye = matrix(data=c(68,15,5,20,119,54,29,84,26,14,14,17,7,10,16,94),nrow = 4,ncol = 4,byrow=T,
dimnames = list(c('black','brunette','red','blond'),c('brown','hazel','green','blue')))
haireye
# 전체합, 행별 합, 열별 합
margin.table(haireye)
margin.table(haireye,margin = 1) # 행별 합
margin.table(haireye,margin = 2) # 열별 합
apply(haireye,1,sum)
apply(haireye,2,sum)
windows()
par(mfrow=c(2,2))
barplot(margin.table(haireye,margin = 1))
pie(margin.table(haireye,margin = 1))
barplot(margin.table(haireye,margin = 2))
pie(margin.table(haireye,margin = 2))
windows()
par(mfrow=c(2,2))
barplot(haireye)
barplot(haireye,beside = T)
mosaicplot(haireye,main='머리색깔 vs. 눈색깔',color=T) # 모자이크 플롯 처음 알게됨...^^
# transpose
t(haireye)
windows()
par(mfrow=c(2,2))
barplot(t(haireye))
barplot(t(haireye),beside = T)
mosaicplot(t(haireye),main='머리색깔 vs. 눈색깔',color=T) # 모자이크 플롯 처음 알게됨...^^
library(gmodels)
CrossTable(haireye)
# brunette과 red인 경우, 눈색깔이 비율의 차이가 커 보이지 않고 독립성 검정에서도 p-value가 0.05보다 크므로 독립이라고 보기 힘들다
# 따라서, 머리색깔이 brunette과 red인 경우에 눈색깔이 비율이 다르다고 볼 수 있는 증거가 부족하다.
CrossTable(haireye,expected = T,prop.t = F,prop.chisq = F,prop.c = F,chisq = T)
CrossTable(haireye,expected = T,resid=T,sresid = T,asresid = T)
?CrossTable
CrossTable(haireye,prop.t = F,prop.chisq = F,prop.c = F,chisq = T)
CrossTable(haireye[2:3,],prop.t = F,prop.chisq = F,prop.c = F,chisq = T)
graphics.off()
rm(list=ls())
### 비모수 검정 ###
# 랜덤 표본 추출
dat = rchisq(20,5)
dat
windows()
par(mfrow=c(1,2))
hist(dat)
boxplot(dat)
# 기술통계량
mean(dat);median(dat)
sd(dat)
skewness(dat)
kurtosis(dat)
windows()
qqnorm(dat)
qqline(dat,col=2,lwd=3)
# 정규성 검정
# lillie.test(dat) # n<30 이므로 성능(power)가 떨어진다.
ad.test(dat)
shapiro.test(dat)
windows()
hist(dat,freq=F)
abline(v=median(dat),col=2)
# Si = { 1  (Xi - M0 > 0)
#     { 0  (Xi - M0 < 0) 단 X1 - M0 = 0 은 제외
# 확률변수 Si는 위와 같다.
# 검정통계량 B = sum(Si) 즉, 중앙값을 초과한 자료의 개수를 의미
# 귀무가설하 Si는 1이 될 확률이 1/2이고, 서로 독이므로  B의 분포는 B(n, 1/2)인 이항분포를 따른다
# 귀무가설하 B의 평균 = n/2, 분산은 var(B) = n/4 이다.
# 표준화된 통계량 = B-(n/2)/(sqrt(n/4))
# 여기서 n은 Xi - M = 0인 Xi를 제외한 자료의 개수
# p_value가 0.05보다 크면 귀무가설을 기각할 수 없다.
# H0 : M = 8 vs. H1 : M != 8, M : 확률변수 X의 중앙값
n = length(dat[dat != 8])
B = length(dat[dat>8])
# 표준화 값
Zb = (B - (n/2))/(sqrt(n/4))
Zb
library(BSDA) # 부호 검정 관련 package
SIGN.test(dat,md = 8,alternative = "two.sided")
### 비모수 검정 ###
# 윌콕슨 부호순위 검정
# 가정 : 중앙값을 중심으로 대칭인 분포를 갖는다.
X = rchisq(20000,5)
x = sample(X,size=20,replace = T)
windows()
par(mfrow=c(1,2))
hist(x)
abline(v=median(x),col=2)
boxplot(x)
windows()
qqnorm(x)
qqline(x,col=2,lty=2)
# 정규성 검정
shapiro.test(x)
ad.test(x)
### 비모수 검정 ###
# 윌콕슨 부호순위 검정
# 가정 : 중앙값을 중심으로 대칭인 분포를 갖는다.
X = rchisq(20000,5)
x = sample(X,size=20,replace = T)
# 정규성 검정
shapiro.test(x)
ad.test(x)
windows()
qqnorm(x)
qqline(x,col=2,lty=2)
# 윌콕슨 부호 검정
# H0 = theta = 6 vs. theta != 6
library(nortest)
wilcox.test(x,mu = 6, alternative = "two.sided")
rm(list=ls())
### 인천광역시 아파트 매매가격(y값) EDA ###
setwd('C:/Users/wndy4/Desktop/Project_DEMA')
library(psych)
library(gmodels)
library(moments)
library(qcc)
## load csv
dat = read.csv('정동호/단지별변수(수정).csv',header=T,stringsAsFactors=F)
str(dat)
price = dat$매매평균..당가.만원.
price
## 그래프
# 히스토그램
hist.price = hist(price)
windows()
hist(price,freq = F)
lines(x = hist.price$mids,y = hist.price$density,type='b',pch=1)
windows()
pareto.chart(price)
# boxplot
windows()
boxplot(price,main = '인천아파트 평균 매매가격')
# outlier 가 많은 것처럼 보인다.
box.price = boxplot(price)
length(box.price$out) # outlier 개수가 129개
## 기술통계량
# 위치측도
mean(price)
median(price)
# 모양측도(왜도,첨도)
skewness(price) # 1.31 # 왜도
kurtosis(price) # 5.88 # 첨도
# 왜도가 0인지 아닌지 검정
agostino.test(price) # p-value가 유의수준 0.05보다 크면 대립가설 기각(왜도가 0이라 할 수 있다.)
# 첨도가 3인지 아닌지 검정
anscombe.test(price) # p-value가 유의수준 0.05보다 크면 귀무가설 기각X(첨도가 3이라 할 수 있다.)
windows()
qqnorm(price)
qqline(price)
# 직접 정규확률그림 그려보기
# 자료 오름차순 정렬
sort.price = sort(price)
sort.price
length(sort.price)
# 표준정규분포에서 각각 1/(n+1) 구간의 확률을 갖는 값을 구하기
norm.price = c()
for(i in 1:length(sort.price)){
norm.price[i] = qnorm((i/(length(sort.price)+1)),0,1)
}
windows()
plot(sort.price ~ norm.price, type='p')
windows()
qqnorm(price)
# 모양으로 보아 skewed right이다.
qq.price = qqnorm(price)
norm.price == qq.price$y
qq.price$y
norm.price == qq.price$x
qq.price$x
norm.price == sort(qq.price$x)
# 정규성 검정
# kolmogorov smirnov test
library(nortest)
lillie.test(price)
# Anderson-Darling test
ad.test(price)
# shapiro-Wilk test
shapiro.test(price)
log.price = log(price)
sqrt.price = sqrt(price)
windows()
par(mfrow=c(2,2))
hist(price)
hist(log.price, main = "로그변환")
boxplot(price)
boxplot(log.price,main = "로그변환")
# 기술통계량
mean(log.price);median(log.price)
# 왜도, 첨도
skewness(log.price)
kurtosis(log.price)
# 왜도 0인지 아닌지 검정
agostino.test(log.price)
# p-value가 유의수준 0.05보다 매우 작으므로 왜도가 0이라하기 힘들다
# 첨도 3인지 아닌지 검정
anscombe.test(log.price)
windows()
qqnorm(log.price)
qqline(log.price)
# 로그변환 후 그림상으로는 정규분포를 따른다고 추론은 할 수 있다. 정규성 검정을 통해 정확히 파악해보자
# 정규성 검정
lillie.test(log.price)
# p-value가 유의수준 0.05보다 매우 작으므로 정규분포를 따른다고 하기 힘들다
ad.test(log.price)
# p-value가 유의수준 0.05보다 매우 작으므로 정규분포를 따른다고 하기 힘들다
shapiro.test(log.price)
## 가설검정 ##
# 표본평균
mean(price)
# 가설검정
# H0 : mu = 250 vs. H1 : mu != 250
# 검정통계량 계산
# 정규성 검정을 통해 표본이 정규분포로 나왔다고 보기 힘들고 자료의 수가 30 이상이므로 t분포 사용
mu = 250
x_bar = mean(price)
s = sd(price)
n = length(price)
# 검정 통계량
t_val = (x_bar - mu)/(s/sqrt(n))
# 유의수준
alpha = 0.05
# p_value 구하기
t_val
p_value = 2*pt(t_val,df=n-1)
p_value
# t.test 사용
t.test(price,mu=250)
# p_value 구하기
p_value = pt(abs(t_val),n-1,lower.tail = F)
p_value
rm(list=ls())
### 비모수 검정 ###
# 윌콕슨 부호순위 검정
# 가정 : 중앙값을 중심으로 대칭인 분포를 갖는다.
X = rchisq(20000,5)
x = sample(X,size=20,replace = T)
windows()
par(mfrow=c(1,2))
hist(x)
abline(v=median(x),col=2)
boxplot(x)
windows()
qqnorm(x)
qqline(x,col=2,lty=2)
# 정규성 검정
shapiro.test(x)
ad.test(x)
rm(list=ls())
### 인천광역시 아파트 매매가격(y값) EDA ###
setwd('C:/Users/wndy4/Desktop/Project_DEMA')
library(psych)
library(gmodels)
library(moments)
library(qcc)
## load csv
dat = read.csv('정동호/단지별변수(수정).csv',header=T,stringsAsFactors=F)
price = dat$매매평균..당가.만원.
## 그래프
# 히스토그램
hist.price = hist(price)
windows()
hist(price,freq = F)
lines(x = hist.price$mids,y = hist.price$density,type='b',pch=1)
windows()
boxplot(price,main = '인천아파트 평균 매매가격')
# 모양측도(왜도,첨도)
skewness(price) # 1.31 # 왜도
kurtosis(price) # 5.88 # 첨도
# 왜도가 0인지 아닌지 검정
agostino.test(price) # agostino.test :  p-value가 유의수준 0.05보다 크면 대립가설 기각(왜도가 0이라 할 수 있다.)
# 첨도가 3인지 아닌지 검정
anscombe.test(price) # anscombe.test : p-value가 유의수준 0.05보다 크면 귀무가설 기각X(첨도가 3이라 할 수 있다.)
windows()
qqnorm(price)
qqline(price)
windows()
qqnorm(price)
qqline(price,col=2)
# 머리색깔과 눈색깔
haireye = matrix(data=c(68,15,5,20,119,54,29,84,26,14,14,17,7,10,16,94),nrow = 4,ncol = 4,byrow=T,
dimnames = list(c('black','brunette','red','blond'),c('brown','hazel','green','blue')))
CrossTable(haireye)
CrossTable(haireye,chisq=T)
CrossTable(haireye[2:3,],prop.t = F,prop.chisq = F,prop.c = F,chisq = T)
