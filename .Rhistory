M = ceiling(N*level) # 신뢰구간을 따르는 표본의 수
nCI = N-M # 가능한 신뢰구간의 수
CI.width = rep(0,nCI) # 가능한 신뢰구간의 수만큼 벡터 생성
for(i in 1:nCI)CI.width[i] = theta.sort[i+M]-theta.sort[i] # 신뢰구간의 길이 계산
index = which.min(CI.width) # 구간 중 가장 짧은 길이의 인덱스 값
HPD = c(theta.sort[index],theta.sort[index+M]) # 해당 길이의 theta값
return(HPD)
}
HPDsample(theta = theta,level = 0.95)
# theta의 사후 표본 생성
theta = rbeta(100,a+x,n-x+b)
HPDsample(theta = theta,level = 0.95)
# theta의 사후 표본 생성
pos_theta = rbeta(100,a+x,n-x+b)
HPDsample(theta = pos_theta,level = 0.95)
# theta의 사후 표본 생성
pos_theta = rbeta(100,a+x,n-x+b)
HPDsample(theta = pos_theta,level = 0.95)
## (4)
# theta의 사전표본
pri_theta = rbeta(100,a,b)
pos_theta = rbeta(100,a+x,n-x+b)
pos_eta = log(pos_theta/(1-pos_theta))
rm(list=ls())
### 5장 2번
## (1)
a = 2; b = 8; n = 10; x = 2
## (3)
# theta의 사후 표본을 이용하는 HPD구간 함수
HPDsample = function(theta,level = 0.95){
N=length(theta) #표본의 수
theta.sort = sort(theta) # 오름차순 정렬
M = ceiling(N*level) # 신뢰구간을 따르는 표본의 수
nCI = N-M # 가능한 신뢰구간의 수
CI.width = rep(0,nCI) # 가능한 신뢰구간의 수만큼 벡터 생성
for(i in 1:nCI)CI.width[i] = theta.sort[i+M]-theta.sort[i] # 신뢰구간의 길이 계산
index = which.min(CI.width) # 구간 중 가장 짧은 길이의 인덱스 값
HPD = c(theta.sort[index],theta.sort[index+M]) # 해당 길이의 theta값
return(HPD)
}
# theta의 사후 표본 생성
set.seed(1234) # 씨드 설정
pos_theta = rbeta(100,a+x,n-x+b)
# 95%수준의 최대사후구간
HPDsample(theta = pos_theta,level = 0.95)
## (4)
# theta의 사전표본
pri_theta = rbeta(100,a,b)
pos_theta = rbeta(100,a+x,n-x+b)
# 95%수준의 최대사후구간
HPDsample(theta = pos_theta,level = 0.95)
pri_eta = log(pri_theta/(1-pri_theta))
pos_eta = log(pos_theta/(1-pos_theta))
windows()
plot(density(pos_eta),type='l',lwd = 2,lty=2,xlab="density")
lines(density(pri_eta),lwd=1, lty=1)
pri_theta = rbeta(1000,a,b)
# theta의 사후표본
pos_theta2 = rbeta(1000,a+x,n-x+b)
# 사전표본 오즈비
pri_eta = log(pri_theta/(1-pri_theta))
# 사후표본 오즈비
pos_eta = log(pos_theta2/(1-pos_theta2))
windows()
plot(density(pos_eta),type='l',lwd = 2,lty=2,xlab="density",main = "사전표본 오즈비와 사후표본 오즈비 비교")
lines(density(pri_eta),lwd=1, lty=1)
# 최대사후구간
HPD = HPDsample(theta = pos_eta,level = 0.95)
abline(v = HPD,lwd = 2, lty =3 ,col=2)
legend("topright",legend=c("사후밀도함수","사전밀도함수","최대사후구간"),lty = c(2,1,3),
col = c("black","black","red"))
windows()
plot(density(pos_eta),type='l',lwd = 2,lty=2,xlab="eta",ylab = "density",
main = "사전표본 오즈비와 사후표본 오즈비 비교")
lines(density(pri_eta),lwd=1, lty=1)
abline(v = HPD,lwd = 2, lty =3 ,col=2)
legend("topright",legend=c("사후밀도함수","사전밀도함수","최대사후구간"),lty = c(2,1,3),
col = c("black","black","red"))
### 5장 4번
n = 12; x = 3
### 5장 4번
n = 12; x = 3
# 12번의 독립적인 베루느이 시행 중 세번의 성공이 관측이라 가정
# 사전분포를 1 즉 beta(1,1)로 둔다.
a = 1; b = 1
# X_13 = 1 의 예측 확률은 결국 (a+x)/(a+b+n)이므로 사후분포의 평균 값이다.
X_13.prob = (a+x)/(a+b+n)
X_13.prob
### 5장 6번
# 그룹 1
n1 = 20; x1 = 10
# 그룹 2
n2 = 20; x2 = 14
# 사전분포는 beta(1,1)
a = 1; b = 1
# 그룹1의 사후분포는 beta(1+10,20-10+10) -> beta(11,20)이고
# 그룹2의 사후분포는 beta(1+14,20-14+1) -> beta(15,7) 이다.
# 각그룹별 사후표본 생성
theta_1 = rbeta(1000,11,20)
theta_2 = rbeta(1000,15,7)
# 로그오즈비
xi = log((theta_1/(1-theta_1)) / (theta_2/(1-theta_2)))
# 몬테칼로 방법(결국 사후표본으로 추정) 로그오즈비 추정치와 표준오차 게산
mean(xi)
# 몬테칼로 방법(결국 사후표본으로 추정) 로그오즈비 추정치와 표준오차 게산
mean(xi); sd(xi)
# 로그오즈비 사후밀도함수와 95% HPD 표시
HPD = HPDsample(theta = xi,level = 0.95)
windows()
plot(density(xi),type = 'l',lwd = 3,ylab = 'density',xlab = '로즈오즈비',
main = '로그오즈비 사후밀도함수와 HPD')
abline(v = HPD,lwd=2,lty=2,col=2)
legend("topright",legend=c("사후밀도함수","95% 최대사후구간"),lwd=c(3,2),col = c("black",2))
windows()
plot(density(xi),type = 'l',lwd = 3,ylab = 'density',xlab = '로즈오즈비',
main = '로그오즈비 사후밀도함수와 HPD')
abline(v = HPD,lwd=2,lty=2,col=2)
legend("topright",legend=c("사후밀도함수","95% 최대사후구간"),lwd=c(3,2),lty = c(1,2),col = c("black",2))
rm(list=ls())
theta_1 = seq(0.1,0.9,by=0.1)
prior_theta = 1/9
# 가능도 함수
lh_dist = (theta_1^nx)*((1-theta_1)^(5-nx))
lh_dist
# x에 대한 marginal dist
marg_dist = sum(lh_dist*prob_theta)
# posterior dist
pos_dist = (lh_dist*prob_theta)/marg_dist
pos_dist
# theta = 0.5일때 posterior dist 확률
pos_dist[5]
nx = 3
# 사전분포는 이산균일분포를 따른다
theta_1 = seq(0.1,0.9,by=0.1)
prior_theta = 1/9
# 가능도 함수
lh_dist = (theta_1^nx)*((1-theta_1)^(5-nx))
lh_dist
# x에 대한 marginal dist
marg_dist = sum(lh_dist*prob_theta)
# posterior dist
pos_dist = (lh_dist*prob_theta)/marg_dist
pos_dist
# theta = 0.5일때 posterior dist 확률
pos_dist[5]
nx = 3
# 사전분포는 이산균일분포를 따른다
theta_1 = seq(0.1,0.9,by=0.1)
prior_theta = 1/9
# 가능도 함수
lh_dist = (theta_1^nx)*((1-theta_1)^(5-nx))
lh_dist
# x에 대한 marginal dist
marg_dist = sum(lh_dist*prob_theta)
# posterior dist
pos_dist = (lh_dist*prob_theta)/marg_dist
pos_dist
# theta = 0.5일때 posterior dist 확률
pos_dist[5]
### 3장 4번
# x의 개수
# (x1,x2,x3,x4,x5) = (1,1,0,0,1)
nx = 3
# 사전분포는 이산균일분포를 따른다
theta_1 = seq(0.1,0.9,by=0.1)
prior_theta = 1/9
# 가능도 함수
lh_dist = (theta_1^nx)*((1-theta_1)^(5-nx))
lh_dist
# x에 대한 marginal dist
marg_dist = sum(lh_dist*prob_theta)
# posterior dist
pos_dist = (lh_dist*prob_theta)/marg_dist
rm(list=ls())
### 3장 4번
# x의 개수
# (x1,x2,x3,x4,x5) = (1,1,0,0,1)
nx = 3
# 사전분포는 이산균일분포를 따른다
theta_1 = seq(0.1,0.9,by=0.1)
prior_theta = 1/9
# 가능도 함수
lh_dist = (theta_1^nx)*((1-theta_1)^(5-nx))
lh_dist
# x에 대한 marginal dist
marg_dist = sum(lh_dist*prior_theta)
# posterior dist
pos_dist = (lh_dist*prior_theta)/marg_dist
pos_dist
# theta = 0.5일때 posterior dist 확률
pos_dist[5]
windows()
plot(x = theta, y = pos_dist)
plot(x = theta_1, y = pos_dist)
windows()
plot(x = theta_1,type='h', y = pos_dist)
### 3장 5번
# (1)
lh_dist[5]
# 0.03125
# (2)
marg_dist
### 5장 2번
## (1)
a = 2; b = 8; n = 10; x = 2
theta = seq(0,1,length=100)
prior.theta = dbeta(theta,a,b)
post.theta = dbeta(theta,a+x,n-x+b) # conjugate prior에 따른 사후분포 또한 베타분포를 따른다
windows()
plot(x = theta,y=post.theta,col=2,type='l')
lines(x = theta,y= prior.theta)
legend("topright",legend=c(paste("beta(",a+x,",",n-x+b,") posterior"),
paste("beta(",a,",",b,") prior")),lty=c(1,1), col=c(2,"black"))
## (3)
# theta의 사후 표본을 이용하는 HPD구간 함수
HPDsample = function(theta,level = 0.95){
N=length(theta) #표본의 수
theta.sort = sort(theta) # 오름차순 정렬
M = ceiling(N*level) # 신뢰구간을 따르는 표본의 수
nCI = N-M # 가능한 신뢰구간의 수
CI.width = rep(0,nCI) # 가능한 신뢰구간의 수만큼 벡터 생성
for(i in 1:nCI)CI.width[i] = theta.sort[i+M]-theta.sort[i] # 신뢰구간의 길이 계산
index = which.min(CI.width) # 구간 중 가장 짧은 길이의 인덱스 값
HPD = c(theta.sort[index],theta.sort[index+M]) # 해당 길이의 theta값
return(HPD)
}
# theta의 사후 표본 생성
set.seed(1234) # 씨드 설정
pos_theta = rbeta(100,a+x,n-x+b)
# 95%수준의 최대사후구간
HPDsample(theta = pos_theta,level = 0.95)
pri_theta = rbeta(1000,a,b)
# theta의 사후표본
pos_theta2 = rbeta(1000,a+x,n-x+b)
# 사전표본 오즈비
pri_eta = log(pri_theta/(1-pri_theta))
# 사후표본 오즈비
pos_eta = log(pos_theta2/(1-pos_theta2))
# 최대사후구간
HPD = HPDsample(theta = pos_eta,level = 0.95)
windows()
plot(density(pos_eta),type='l',lwd = 2,lty=2,xlab="eta",ylab = "density",
main = "사전표본 오즈비와 사후표본 오즈비 비교")
lines(density(pri_eta),lwd=1, lty=1)
abline(v = HPD,lwd = 2, lty =3 ,col=2)
legend("topright",legend=c("사후밀도함수","사전밀도함수","최대사후구간"),lty = c(2,1,3),
col = c("black","black","red"))
### 5장 4번
n = 12; x = 3
# 12번의 독립적인 베루느이 시행 중 세번의 성공이 관측이라 가정
# 사전분포를 1 즉 beta(1,1)로 둔다.
a = 1; b = 1
# posterior dist
theta = seq(0,1,length=50)
post.dist = dbeta(theta,a+x,n-x+b)
# X_13 = 1 의 예측 확률은 결국 (a+x)/(a+b+n)이므로 사후분포의 평균 값이다.
X_13.prob = (a+x)/(a+b+n)
X_13.prob
### 5장 6번
# 그룹 1
n1 = 20; x1 = 10
# 그룹 2
n2 = 20; x2 = 14
# 사전분포는 beta(1,1)
a = 1; b = 1
# 그룹1의 사후분포는 beta(1+10,20-10+10) -> beta(11,20)이고
# 그룹2의 사후분포는 beta(1+14,20-14+1) -> beta(15,7) 이다.
# 각그룹별 사후표본 생성
theta_1 = rbeta(1000,11,20)
theta_2 = rbeta(1000,15,7)
# 로그오즈비
xi = log((theta_1/(1-theta_1)) / (theta_2/(1-theta_2)))
# 몬테칼로 방법(결국 사후표본으로 추정) 로그오즈비 추정치와 표준오차 게산
mean(xi); sd(xi)
# 로그오즈비 사후밀도함수와 95% HPD 표시
HPD = HPDsample(theta = xi,level = 0.95)
windows()
plot(density(xi),type = 'l',lwd = 3,ylab = 'density',xlab = '로즈오즈비',
main = '로그오즈비 사후밀도함수와 HPD')
abline(v = HPD,lwd=2,lty=2,col=2)
legend("topright",legend=c("사후밀도함수","95% 최대사후구간"),lwd=c(3,2),lty = c(1,2),col = c("black",2))
rm(list=ls())
y1 = rnorm(100,4,1)
y2 = rnorm(50,6,2)
windows()
par(mfrow=c(1,2))
hist(y1)
hist(y2)
windows()
par(mfrow=c(1,2))
hist(y1)
hist(y2)
windows()
par(mfrow=c(2,1))
hist(y1)
hist(y2)
summary(y1)
summary(y2)
windows()
par(mfrow=c(2,1))
hist(y1,xlim = c(0,11))
hist(y2,xlim = c(0,11))
abline(v=mean(y1),col=2)
summary(y1)
abline(v=mean(y2),col=2)
windows()
par(mfrow=c(2,1))
hist(y1,xlim = c(0,11))
abline(v=mean(y1),col=2)
hist(y2,xlim = c(0,11))
abline(v=mean(y2),col=2)
windwos()
hist(y1,xlim=c(0,11),col=rgb(1,0,0,0.5),freq = F)
hist(y1,xlim=c(0,11),col=rgb(0,0,0,0.5),freq = F ,add=T)
windows()
hist(y1,xlim=c(0,11),col=rgb(1,0,0,0.5),freq = F)
hist(y1,xlim=c(0,11),col=rgb(0,0,0,0.5),freq = F ,add=T)
windows()
hist(y1,xlim=c(0,11),col=rgb(1,0,0,0.5),freq = F)
hist(y2,xlim=c(0,11),col=rgb(0,0,0,0.5),freq = F ,add=T)
windows()
hist(y1,xlim=c(min(y1)-1,max(y1)+1),col=rgb(1,0,0,0.5),freq = F)
hist(y2,xlim=c(min(y1)-1,max(y1)+1),col=rgb(0,0,0,0.5),freq = F ,add=T)
# density plot
d1 = density(y1)
d2 = density(y2)
windows()
plot(d1,xlim=c(0,11))
lines(d2,xlim=c(0,11),col=2)
windows()
plot(d1,xlim=c(0,11))
lines(d2,xlim=c(0,11),col=2)
windows()
qqplot(y1,y2)
windows()
qqplot(y1,y2)
abline(a=0,b=1,col=2,lty=2)
tmp1 = rnorm(100,4,1)
tmp2 = rnorm(50,6,1)
windows()
qqplot(tmp1,tmp2)
abline(a=0,b=1,col=2,lty=2)
tmp1 = rnorm(100,4,1)
tmp2 = rnorm(50,6,3)
windows()
qqplot(tmp1,tmp2)
abline(a=0,b=1,col=2,lty=2)
windows()
qqplot(tmp1,tmp2)
abline(a=0,b=1,col=2,lty=2)
# 표준편차만 다를 경우 기울기는 다르다는 것을 확인할 수 있다.
graphics.off()
mean1 = mean(y1)
mean2 = mean(y2)
var1 = var(y1)
var2 = var(y2)
sd1 = sd(y1)
sd2=sd(y2)
n1=length(y1)
n2=length(y2)
mean1;mean2
var1;var2
# 정규성 검정
shapiro.test(y1)
shapiro.test(y2)
library(moments)
library(nortest)
lillie.test(y1)
lillie.test(y2)
#######
skewness(y1)
skewness(y2)
agostino.test(y1)
agostino.test(y2)
kurtosis(y1)
kurtosis(y2)
anscombe.test(y1)
anscombe.test(y2)
agostino.test(y1)
agostino.test(y2)
anscombe.test(y1)
anscombe.test(y2)
#######
skewness(y1)
skewness(y2)
agostino.test(y1)
agostino.test(y2)
kurtosis(y1)
kurtosis(y2)
anscombe.test(y1)
anscombe.test(y2)
lillie.test(y1)
lillie.test(y2)
# 틍분산 검정
var.test(y1,y2)
# 두 분산이 같다는 가정 하에 평균 검정(t 검정)
var_pooled = ((n1-1)*var1 + (n2-1)*var2))/(n1+n2-2)
# 두 분산이 같다는 가정 하에 평균 검정(t 검정)
var_pooled = ((n1-1)*var1 + (n2-1)*var2)/(n1+n2-2)
t1 = (mean1-mean2)/sqrt(var_pooled)
p_val = 2*pt(abs(t1),df=n1+n2-2)
p-val
p_val
p_val = 2*(1-pt(abs(t1),df=n1+n2-2))
p_val
t.test(y1,y2,var.equal = T)
t1
# 두 분산이 다르다는 가정 하 평균 검정
t2 = (mean1-mean2)/sqrt((var/n1 + var/n2))
# 두 분산이 다르다는 가정 하 평균 검정
t2 = (mean1-mean2)/sqrt((var1/n1 + var2/n2))
# ~ 자유도
w1 = var1/n1
w2 = var2/n2
df = (w1+w2)^2/(w1^2/(n1-1)+w2^2/(n2-1))
t.test(y1,y2,var.equal = F)
t2
df.sw = (w1+w2)^2/(w1^2/(n1-1)+w2^2/(n2-1))
pval2  = 2*(1-pt(abs(t2),df=df.sw))
pval2
t.test(y1,y2,var.equal = F)
# 교과서 자유도
df.1 = min(n1-1,n2-1)
pval3  = 2*(1-pt(abs(t2),df=df.1))
pval3
# 두모집단이 정규분포가 아니더라도 표본이 충분하다면
# 중심극한정리를 이용하여 검정을 수행할 수 있다.
pval4 = 2*(1-pnorm(abs(t2)))
pval4
# 비모수 검정
# 각 모집단이 정규분포를 따른다고 보기 힘들고 표본의 크기가 충분치 않을 경우
# 비모수 검정을 수행할 수 있다.
wilcox.test(y1,y2)
# 두분포가 다른디 검정
ks.test(y1,y2)
tmp1 = rnorm(100,4,1)
tmp2 = rnorm(50,6,1)
ks.test(tmp1,tmp2)
tmp1 = rnorm(100,6,1)
tmp2 = rnorm(50,6,4)
ks.test(tmp1,tmp2)
data(iris)
head(iris)
species = iris$Species
swidth = iris$Sepal.Width
# summary
summary(swidth)
windows()
hist(swidth)
rm(list=ls())
### train set, validation set, test set 나누기
setwd("C:/Users/wndy4/Desktop/Project_DEMA")
# 데이터 불러오기
dat = read.csv("단지별변수(new).csv",header=T,stringsAsFactors=F)
nrow(dat)
# seed 설정
set.seed(1234)
order(runif(10))
order(runif(10))
dat.rand = dat[order]
order(runif(10))
# seed 설정
set.seed(1234)
order(runif(10))
order(runif(10))
order(runif(10))
order(runif(10))
order(runif(10))
# seed 설정
set.seed(1234)
order(runif(10))
dat.rand = dat[order(runif(nrow(dat))),]
View(dat.rand)
# 데이터 split -> train set, validation set, test set
# 4:3:3의 비율
nrow(dat)/10
# 데이터 split -> train set, validation set, test set
# 4:3:3의 비율
ratio = nrow(dat)/10
# 데이터 split -> train set, validation set, test set
# 4:3:3의 비율
r = nrow(dat)/10
4*r
3*r
3*r
sum(4*r,3*r,3*3)
sum(4*r,3*r,3*r)
4*r
# train은 1:1195
1196+895
2091-1196
2090-1196
2090-1196+1
nrow(dat)
2985-2091
# 데이터 split -> train set, validation set, test set
# 4:3:3의 비율
# train은 1:1195
# validation은 1196:2090
# test은 2091:2985
# train set, validation set, test set 생성
train = dat.rand[1:1195,]
valid = dat.rand[1196:2090,]
test = dat.rand[2091:2985,]
nrow(train)
nrow(valid)
nrow(test)
sum(nrow(train),nrow(valid),nrow(test))
# 각각의 파일로 저장
write.csv(train,"train set.csv")
write.csv(valid,"validation set.csv")
write.csv(test,"test set.csv")
